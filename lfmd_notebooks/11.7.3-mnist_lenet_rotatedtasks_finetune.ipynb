{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "##\n",
    "from repo import REPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml = \"\"\"\n",
    "run_config:\n",
    "  exec_type: parallel # sequential\n",
    "  hostname: gorilla\n",
    "  gpu_ids: [0,1,2,3,4,5,6,7]\n",
    "  runs_per_gpu: 3\n",
    "\n",
    "  wandb: # wandb config for run_handler, if \"wandb: null\" then logging to wandb is disabled for run_handler\n",
    "    init:\n",
    "      tags:\n",
    "        - ${config.experiment_data.experiment_tag}_exps\n",
    "        - run_handler\n",
    "      notes: #\n",
    "      group: ${config.experiment_data.experiment_tag}\n",
    "      job_type: run_handler\n",
    "\n",
    "seeds: [1,2,3]\n",
    "\n",
    "sweep:\n",
    "  type: grid\n",
    "  axes:\n",
    "    - parameter: trainer.init_model_step\n",
    "      vals: [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475]\n",
    "    - parameter: data.dataset_kwargs.rotation_angle\n",
    "      vals: linspace(0,180,50,endpoint=True)\n",
    "    - parameter: data.dataset_split.restrict_n_samples_train_task\n",
    "      vals: [300] #[5, 20, 50, 100, 500, 1000, 10000, 48000]\n",
    "\n",
    "start_num: 3 # use this to count how often this config is run\n",
    "###\n",
    "config:\n",
    "  experiment_data:\n",
    "    entity: jkuiml-fsl\n",
    "    project_name: sparsity\n",
    "    experiment_tag: \"11.7\"\n",
    "    experiment_type: startnum_${start_num}\n",
    "    experiment_name: mnist-${config.experiment_data.experiment_tag}.${start_num}-lenet_rottasks_ft\n",
    "    experiment_dir: null\n",
    "    experiment_notes: Hyperparameter search.\n",
    "    job_name: null\n",
    "    seed: 0\n",
    "    hostname: null # the server on which the run is run, will be filled by run_handler\n",
    "    gpu_id: 0\n",
    "\n",
    "  # wandb:\n",
    "  #   init:\n",
    "  #     tags: # list(), used to tag wandblogger\n",
    "  #       - ${config.experiment_data.experiment_tag}_exps\n",
    "  #     notes: ${config.experiment_data.experiment_notes} # str, used to make notes to wandblogger\n",
    "  #     group: ${config.experiment_data.experiment_tag} # null\n",
    "  #     job_type: ${config.experiment_data.experiment_type} # examples: hypsearch, pretrain, eval, etc.\n",
    "\n",
    "  #   watch:\n",
    "  #     log: null #parameters #null #all\n",
    "  #     log_freq: 5000\n",
    "\n",
    "  model:\n",
    "    name: fc\n",
    "    model_kwargs:\n",
    "      input_size: 784\n",
    "      hidden_sizes:\n",
    "        - 300\n",
    "        - 100\n",
    "      output_size: 10\n",
    "      flatten_input: True\n",
    "      dropout: null\n",
    "      act_fn: relu\n",
    "\n",
    "  trainer:\n",
    "    training_setup: supervised\n",
    "    n_steps: 2000\n",
    "    log_train_step_every: 1\n",
    "    log_additional_train_step_every_multiplier: 1\n",
    "    log_additional_logs: True\n",
    "    val_every: 5\n",
    "    save_every: 5 #500\n",
    "    early_stopping_patience: 200 #500\n",
    "    batch_size: 128\n",
    "    optimizer_scheduler:\n",
    "      optimizer_name: adamw #sgd #adamw\n",
    "      optimizer_kwargs:\n",
    "        lr: 0.001\n",
    "        weight_decay: 0.0\n",
    "    \n",
    "    init_model_step: XXX\n",
    "    init_model: /system/user/beck/pwbeck/projects/regularization/erank/outputs/mnist-11.5.0-lenet--221015_122552/model_step_${config.trainer.init_model_step}.p\n",
    "\n",
    "    loss: crossentropy\n",
    "\n",
    "    metrics:\n",
    "      - Accuracy\n",
    "    num_workers: 4\n",
    "    verbose: False\n",
    "\n",
    "  data:\n",
    "    dataset: rotatedvision\n",
    "    dataset_kwargs:\n",
    "      data_root_path: /system/user/beck/pwbeck/data\n",
    "      dataset: mnist\n",
    "      rotation_angle: XXX\n",
    "    dataset_split:\n",
    "      train_val_split: 0.8\n",
    "      restrict_n_samples_train_task: XXX\n",
    "\n",
    "\"\"\"\n",
    "cfg = OmegaConf.create(config_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_sweep.py --config-name mnist-11.7.3-lenet_rottasks_ft.yaml\n"
     ]
    }
   ],
   "source": [
    "print(REPO.create_experiment(cfg, override=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('subspaces')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac019f01eb2a0970f066d5e193a84f30bb43215eeeface9d3d8db32241c79700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
